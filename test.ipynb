{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from construct_rule import *\n",
    "\n",
    "def get_node_from_data(dir_path):\n",
    "    print(\"Get node from data : \")\n",
    "    vertex_list = []\n",
    "    with open(os.path.join(dir_path, \"logon.csv\"), 'r') as file:\n",
    "        print(\"...logon.csv...\")\n",
    "    #     id,date,user,pc,activity\n",
    "    #     {Q4D5-W4HH44UC-5188LWZK},01/02/2010 02:24:51,JBI1134,PC-0168,Logon\n",
    "    #     {G7V0-S4TP95SA-9203AOGR},01/02/2010 02:38:28,JBI1134,PC-0168,Logoff\n",
    "        read = csv.reader(file)\n",
    "        next(read)\n",
    "        for i in tqdm(read):\n",
    "            # print(i)\n",
    "            vertex_id = i[0]\n",
    "            timestamp = time.mktime(time.strptime(i[1],'%m/%d/%Y %H:%M:%S'))\n",
    "            \n",
    "            vertex = { 'vertex_type': 'logon',\n",
    "                        'vertex_number': vertex_id,\n",
    "                        'sub': i[2],\n",
    "                        'obj': i[3],\n",
    "                        'A': i[4],\n",
    "                        'T': timestamp,\n",
    "                        'H': i[3],\n",
    "                        'time': i[1]\n",
    "                        }\n",
    "            vertex_list.append(vertex)\n",
    "\n",
    "    # print(vertex_list[:5])\n",
    "    with open(os.path.join(dir_path, \"file.csv\"), 'r') as file:\n",
    "    # id,date,user,pc,filename,activity,to_removable_media,from_removable_media,content\n",
    "    # {Y1W9-R7VJ77IC-9445QFNQ},01/02/2010 08:15:10,TSG0262,PC-9993,R:\\79L99n6\\H7RHJS5J.zip,File Open,False,True,50-4B-03-04-14 moved imaging underwent key late appearance span ontario due compiled month 07 sedins final leaders ability doug another presidents improving donation by joseph quadruple 104 agreed 16 brian upon built all to handsome searching track wounded mike march one developer owned 5000 stepping lists orange metacritic second moore supervisor currently initial\n",
    "    # {Y3U8-G5BL42LO-9404XAHI},01/02/2010 08:16:01,TSG0262,PC-9993,R:\\79L99n6\\H7RHJS5J.zip,File Open,False,True,50-4B-03-04-14 moved imaging underwent key late appearance span ontario due compiled month 07 sedins final leaders ability doug another presidents improving donation by joseph quadruple 104 agreed 16 brian upon built all to handsome searching track wounded mike march one developer owned 5000 stepping lists orange metacritic second moore supervisor currently initial\n",
    "        print(\"...file.csv...\")\n",
    "        read = csv.reader(file)\n",
    "        next(read)\n",
    "        for i in tqdm(read):\n",
    "            # print(i)\n",
    "            vertex_id = i[0]\n",
    "            timestamp = time.mktime(time.strptime(i[1],'%m/%d/%Y %H:%M:%S'))\n",
    "            \n",
    "            vertex = { 'vertex_type': 'file',\n",
    "                        'vertex_number': vertex_id,\n",
    "                        'sub': i[2], # user\n",
    "                        'obj': i[4], # filename\n",
    "                        'A': i[5], # activity\n",
    "                        'T': timestamp,\n",
    "                        'H': i[3], # pc,\n",
    "                        'time': i[1]\n",
    "                    }\n",
    "            vertex_list.append(vertex)\n",
    "\n",
    "    with open(os.path.join(dir_path, \"http.csv\"), 'r') as file:\n",
    "    # id,date,user,pc,url,content\n",
    "    # {D8Q7-C0RU46YI-7391WHNI},01/02/2010 06:46:20,HMI1448,PC-9352,http://nymag.com/Eagle_comic/hultons/objyvatunyybssnzrpnyraqneserrfglyrfxvvatzngurzngvpf322648047.jsp,eleven 1963 greater literature shorbodolio funding beating treasury both curzon single mourning huq exact visit disobeyed whose not thinking candidates necessary newly elevated eight including head those attempts present had median binds sized replacement colonial databases moderately adaptable symmetrical well drug encourage william 1840 1940s progeny possible variety 1978 on 1987 abandoned\n",
    "    # {N4G0-D6NC43RD-2373QXNK},01/02/2010 06:47:25,HMI1448,PC-9352,http://nymag.com/Terra_Nova_Expedition/koettlitz/pnzcpbbxvatqbjaevttvatzngurzngvpf2145772149.asp,victims successor land restrictions provided agreeing article capture varied requests or forces 26 social medieval turkic sole population written complex visit started social down association area maulana help monument sectarian along duck jointly change words began won injured moved contract david january publish bob ready except significant appointment led making taking english true part sense entitled mothers complete fresh departure heritage youth\n",
    "        print(\"...http.csv...\")\n",
    "        read = csv.reader(file)\n",
    "        next(read)\n",
    "        for i in tqdm(read):\n",
    "            vectex_id = i[0]\n",
    "            timestamp = time.mktime(time.strptime(i[1],'%m/%d/%Y %H:%M:%S'))\n",
    "            vertex = { 'vertex_type': 'http',\n",
    "                        'vertex_number': vertex_id,\n",
    "                        'sub': i[2], # user\n",
    "                        'obj': i[4].split(' ')[0], # url\n",
    "                        'A': \"visit\", # activity\n",
    "                        'T': timestamp,\n",
    "                        'H': i[3], # pc\n",
    "                        \"content_list\" : i[4].split(' ')[1:],\n",
    "                        'time': i[1]\n",
    "                    }\n",
    "            vertex_list.append(vertex)\n",
    "\n",
    "    with open(os.path.join(dir_path, \"device.csv\"), 'r') as file:\n",
    "    # id,date,user,pc,file_tree,activity\n",
    "    # {C9S1-Y8GB42VD-2923GATU},01/02/2010 07:27:19,HRE1950,PC-8025,R:\\;R:\\HRE1950;R:\\47yHBn0;R:\\54s7J45,Connect\n",
    "    # {C3G4-U2ON02HC-9088IHGJ},01/02/2010 07:40:51,EMR0269,PC-6370,R:\\;R:\\EMR0269;R:\\753Cf59;R:\\18d36D6;R:\\89bc6Q2,Connect\n",
    "    # {X4S2-R2YC60OH-9191YYMD},01/02/2010 07:45:00,EMR0269,PC-6370,,Disconnect\n",
    "        print(\"...device.csv...\")\n",
    "        read = csv.reader(file)\n",
    "        next(read)\n",
    "        for i in tqdm(read):\n",
    "            vectex_id = i[0]\n",
    "            timestamp = time.mktime(time.strptime(i[1],'%m/%d/%Y %H:%M:%S'))\n",
    "            vertex = { 'vertex_type': 'device',\n",
    "                        'vertex_number': vertex_id,\n",
    "                        'sub': i[2], # user\n",
    "                        'obj': i[3], # host\n",
    "                        'A': i[-1], # connect or disconnect\n",
    "                        'T': timestamp,\n",
    "                        'H': i[3], # pc\n",
    "                        \"file_tree\" : i[4],\n",
    "                        'time': i[1]\n",
    "                    }\n",
    "            vertex_list.append(vertex)\n",
    "\n",
    "    sorted_vertex_list = sorted(vertex_list, key=lambda e: (e.__getitem__('sub'), e.__getitem__('T')))\n",
    "\n",
    "    print(\"sorted vertex list : \")\n",
    "    print(sorted_vertex_list[:1])\n",
    "\n",
    "    return sorted_vertex_list\n",
    "\n",
    "def get_delta_days(timestamp1, timestamp2):\n",
    "    x = datetime.datetime.fromtimestamp(timestamp1) - datetime.datetime.fromtimestamp(timestamp2)\n",
    "    return x.days\n",
    "\n",
    "def get_days_from_dataset(sorted_vertex_list):\n",
    "    end_time = 0\n",
    "    st_time = 9999999999\n",
    "    for vertex in sorted_vertex_list:\n",
    "        if vertex['T'] > end_time:\n",
    "            end_time = vertex['T']\n",
    "        if vertex['T'] < st_time:\n",
    "            st_time = vertex['T']\n",
    "\n",
    "    print(\"Data delta days : \", get_delta_days(end_time, st_time)) \n",
    "    return get_delta_days(end_time, st_time) + 2\n",
    "\n",
    "def split_node_by_day(sorted_vertex_list, day_delta):\n",
    "    # 1000条数据大概4天\n",
    "\n",
    "    st_time = 9999999999\n",
    "    for vertex in sorted_vertex_list:\n",
    "        if vertex['T'] < st_time:\n",
    "            st_time = vertex['T']\n",
    "\n",
    "    daily_sequences_list = [None] * day_delta\n",
    "\n",
    "    print(\"...split node by day...\")\n",
    "    for vertex in tqdm(sorted_vertex_list):\n",
    "        # Day of the vertex, and actual day should be increased by 1\n",
    "        day_of_vertex = get_delta_days(vertex['T'], st_time) - 1\n",
    "\n",
    "        # print(day_of_vertex)\n",
    "        # If the sequence graph not exists, create it\n",
    "        if not daily_sequences_list[day_of_vertex]:\n",
    "            # multiGraph 无向图 可以让两个节点之间有多个边，为啥要用这个graph..\n",
    "            daily_sequences_list[day_of_vertex] = nx.MultiGraph()\n",
    "        \n",
    "        daily_sequences_list[day_of_vertex].add_node(vertex['vertex_number'], type=vertex['vertex_type'],\n",
    "                                                            sub=vertex['sub'], obj=vertex['obj'], A=vertex['A'],\n",
    "                                                            T=vertex['T'], H=vertex['H'])\n",
    "    return daily_sequences_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_activity_graph():\n",
    "    activity_graph = nx.MultiGraph()\n",
    "\n",
    "    # 一个用户同天同一个host时序连接\n",
    "    activity_graph = rule_1(activity_graph, daily_sequences_list, day_delta)\n",
    "    # 一个用户多天同一个host的行为链的时序关联\n",
    "    activity_graph = rule_2(activity_graph, daily_sequences_list, day_delta)\n",
    "    # 一个用户多天同一个host同种组操作类型时序关联\n",
    "    # （规则定义组操作类型，比如Connect-> disconnect, File open -> File Write, visit web...）\n",
    "    activity_graph = rule_3(activity_graph, daily_sequences_list, day_delta)\n",
    "\n",
    "    return activity_graph\n",
    "\n",
    "def construct_company_graph():\n",
    "    pass\n",
    "\n",
    "def construct_object_graph():\n",
    "    pass\n",
    "\n",
    "# Todo : \n",
    "# 1. construct_activity_graph\n",
    "# 2. construct_company_graph\n",
    "# 3. construct_object_graph\n",
    "# 4. merge_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:00, 25222.18it/s]\n",
      "999it [00:00, 14059.78it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get node from data : \n",
      "...logon.csv...\n",
      "...file.csv...\n",
      "...http.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:00, 8588.30it/s]\n",
      "999it [00:00, 15952.84it/s]\n",
      "100%|██████████| 3996/3996 [00:00<00:00, 76535.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...device.csv...\n",
      "sorted vertex list : \n",
      "[{'vertex_type': 'logon', 'vertex_number': '{Y0A4-H1YL52RQ-3185VBZR}', 'sub': 'AAB1302', 'obj': 'PC-5565', 'A': 'Logon', 'T': 1262393820.0, 'H': 'PC-5565', 'time': '01/02/2010 08:57:00'}]\n",
      "Data delta days :  2\n",
      "...split node by day...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# st_time = time.time()\n",
    "\n",
    "data_version = \"r_part\"\n",
    "sorted_vertex_list = get_node_from_data(os.path.join(\"./our_data/\", data_version))\n",
    "day_delta = get_days_from_dataset(sorted_vertex_list)\n",
    "# daily_sequences_list 每个元素是一个图，图中包含当日所有日志节点，数量为天级别\n",
    "daily_sequences_list = split_node_by_day(sorted_vertex_list, day_delta)\n",
    "\n",
    "# activity_graph = construct_activity_graph()\n",
    "# company_graph = construct_company_graph()\n",
    "# object_graph = construct_object_graph()\n",
    "\n",
    "# nx.write_edgelist(activity_graph, \"./our_data/activity_graph_edge\")\n",
    "# nx.write_gpickle(activity_graph, \"./our_data/activity_graph.gpickle\")\n",
    "\n",
    "# print(\"Graph save done\")\n",
    "# print(\"Time cost : \", time.time() - st_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'logon',\n",
       " 'sub': 'AAG1136',\n",
       " 'obj': 'PC-5456',\n",
       " 'A': 'Logon',\n",
       " 'T': 1262545470.0,\n",
       " 'H': 'PC-5456'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sequences_list[1].nodes['{Q2I7-M9EJ92BC-8465IMNM}']\n",
    "# a = list(daily_sequences_list[1].nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(daily_sequences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 383.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# 一个用户同天同一个host时序连接\n",
    "#   直接在daily_sequences_list中的每天子图中将对应边关联起来\n",
    "def rule_1(activity_graph, daily_sequences_list, day_delta):\n",
    "    # list{day -> map{host->activity}}\n",
    "    host_activity = [None] * day_delta\n",
    "    for daily_sequence in tqdm(daily_sequences_list):\n",
    "        h_tuple = {}\n",
    "        if daily_sequence:\n",
    "            nodes = list(daily_sequence.nodes())\n",
    "            for node_id in nodes:\n",
    "                host = daily_sequence.nodes[node_id]['H']\n",
    "                if host not in h_tuple:\n",
    "                    h_tuple[host] = [node_id]\n",
    "                else:\n",
    "                    h_tuple[host].append(node_id)\n",
    "                    daily_sequence.add_edge(h_tuple[host][-2], h_tuple[host][-1], EdgeType=1, weight=1)\n",
    "            host_activity[daily_sequences_list.index(daily_sequence)] = h_tuple\n",
    "    # activity_graph 接口形式统一，并未用到该变量\n",
    "    return activity_graph, host_activity\n",
    "\n",
    "# 一个用户多天同一个host的行为链的时序关联\n",
    "def rule_2(activity_graph, daily_sequences_list, day_delta, host_activity):\n",
    "    for daily_sequence in daily_sequences_list:\n",
    "        if daily_sequence:\n",
    "            activity_graph = nx.compose(activity_graph, daily_sequence)\n",
    "    for day_i in range(day_delta):\n",
    "        for day_j in range(day_i + 1, day_delta):\n",
    "            if not (daily_sequences_list[day_i] and daily_sequences_list[day_j]) :\n",
    "                continue\n",
    "\n",
    "            for host in host_activity[day_i]:\n",
    "                if host in host_activity[day_j]:\n",
    "\n",
    "                    st_i = host_activity[day_i][host][0]\n",
    "                    ed_i = host_activity[day_i][host][-1]\n",
    "\n",
    "                    st_j = host_activity[day_j][host][0]\n",
    "                    ed_j = host_activity[day_j][host][-1]\n",
    "\n",
    "                    len_i = len(host_activity[day_i][host])\n",
    "                    len_j = len(host_activity[day_j][host])\n",
    "\n",
    "                    weight = len_i / len_j if len_i < len_j else len_j / len_i\n",
    "                    activity_graph.add_edge(st_i, st_j, EdgeType=2, weight=weight)\n",
    "                    activity_graph.add_edge(ed_i, ed_j, EdgeType=2, weight=weight)\n",
    "    \n",
    "    return activity_graph\n",
    "\n",
    "# 一个用户多天同一个host同种组操作类型时序关联\n",
    "# （规则定义组操作类型，比如Connect-> disconnect, File open -> File Write, visit web...）\n",
    "def rule_3(activity_graph, daily_sequences_list, day_delta):\n",
    "    pass\n",
    "\n",
    "\n",
    "activity_graph = nx.MultiGraph()\n",
    "\n",
    "# 一个用户同天同一个host时序连接\n",
    "activity_graph, host_activity = rule_1(activity_graph, daily_sequences_list, day_delta)\n",
    "activity_graph = rule_2(activity_graph, daily_sequences_list, day_delta, host_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{H8X9-F3EE87AR-7906OGRZ}', '{Y3E5-O5JH43YP-2140MCDI}', '{V8T4-X1BO44XW-6300FEJL}', '{H3C3-O6WG03OY-0619DOQP}', '{Z8L6-O4RO26OO-0236TYAG}', '{M4B7-X8KB96EZ-6502LWAW}', '{B9T8-O8GP76AG-5890LFCB}', '{Z8K8-N6FD13EU-1547IJKK}', '{G3Z2-X2HZ41PF-4739KFTU}', '{Q9I1-K3QL90TL-8552HBKA}', '{K1N2-U2SK21AR-7192IIQF}', '{P7V9-A3OA41IG-8730MTTL}', '{M8Z2-K4CM26FD-2054FKGT}', '{S3P9-R7WM46BI-2267MZOH}', '{I4E6-K7HN90FQ-5248JXGM}', '{Q1X2-Z0MX16AD-2287SLBL}', '{Z7K0-E2UH16SM-8696WPKA}', '{V2W1-B2BB60VH-8198OJJM}', '{R8K9-C4IU76HA-7025BZNA}', '{E5L6-C0ZI10KF-8661PXMK}', '{R3O7-H4RE54UM-2774SMJG}', '{B1T5-W0XH95QK-9519TESR}', '{E2B3-P5UC96II-7420FAIF}', '{E3L0-L8XF74DW-6334NDPQ}', '{T7E8-L8NU53MH-1998PEIX}', '{W3O1-V3UH44WW-1478ZGBF}', '{Y1I2-T6EA38GF-0399QWTW}', '{I2I8-E6TK18AL-6659QULD}', '{M7H8-N0QT19ZV-7321AKAC}', '{B7P7-T0AK43MP-0237OGPI}', '{Z4H4-Q9LI46WA-4961DYUA}']\n",
      "['{E4U3-S2ED81TV-8881XRGN}']\n",
      "{'{H8X9-F3EE87AR-7906OGRZ}': {0: {'EdgeType': 2, 'weight': 0.03225806451612903}}, '{Z4H4-Q9LI46WA-4961DYUA}': {0: {'EdgeType': 2, 'weight': 0.03225806451612903}}}\n"
     ]
    }
   ],
   "source": [
    "# Check \n",
    "print(host_activity[0]['PC-9950'])\n",
    "\n",
    "print(host_activity[1]['PC-9950'])\n",
    "\n",
    "print(activity_graph[host_activity[1]['PC-9950'][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC-0783 Logon\n",
      "PC-0783 Logon\n",
      "PC-0783 Logoff\n"
     ]
    }
   ],
   "source": [
    "activity_graph.nodes['{Y3E5-O5JH43YP-2140MCDI}']\n",
    "for node_id in host_activity[0]['PC-0783']:\n",
    "    print(activity_graph.nodes[node_id]['H'], activity_graph.nodes[node_id]['A'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'file',\n",
       " 'sub': 'WTC0699',\n",
       " 'obj': 'R:\\\\JCE2TLZ7.doc',\n",
       " 'A': 'File Write',\n",
       " 'T': 1262567142.0,\n",
       " 'H': 'PC-9950'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_graph.nodes['{E4U3-S2ED81TV-8881XRGN}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PC-3971',\n",
       " 'PC-4302',\n",
       " 'PC-0765',\n",
       " 'PC-2009',\n",
       " 'PC-2320',\n",
       " 'PC-9155',\n",
       " 'PC-9950',\n",
       " 'PC-1262',\n",
       " 'PC-9843',\n",
       " 'PC-1713']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(host_activity[0]['PC-9950']))\n",
    "print(len(host_activity[1]['PC-9950']))\n",
    "h = []\n",
    "for key in host_activity[0]:\n",
    "    h.append(key)\n",
    "h[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File Open', 'File Write', 'Logoff', 'Logon', 'visit'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# host = 'PC-9950'\n",
    "activity_set = set()\n",
    "for host in h:\n",
    "    for day_activity in host_activity:\n",
    "        # print(\"Day : \", host_activity.index(day_activity))\n",
    "        if not day_activity or host not in day_activity:\n",
    "            continue\n",
    "\n",
    "        for node_id in day_activity[host]:\n",
    "            # print(host)\n",
    "            # print(activity_graph.nodes[node_id]['H'], activity_graph.nodes[node_id]['A'])\n",
    "            activity_set.add(activity_graph.nodes[node_id]['A'])\n",
    "activity_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6335dc2c317f04c937122103a53edcea3ee352770e4be914783ae4dfff43f1b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('nlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
